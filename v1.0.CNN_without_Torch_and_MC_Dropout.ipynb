{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1a160c",
   "metadata": {},
   "source": [
    "# <font color=Red># Prologue : CNNs implementation without Torch </font>\n",
    "\n",
    "해당 프로젝트에서는 PyTorch 없이 CNNs를 구현하고, </br>\n",
    "간단한 이미지(MNIST 데이터세트)를 분류하는 Classification Task를 수행합니다. </br>\n",
    "해당 프로젝트의 Experiment Setting은 CNNs Implementation with Torch를 참고합니다. </br> \n",
    "</br>\n",
    "### Preliminary \n",
    "모든 Neural Networks는 세 개의 요소로 구성되어 있습니다. </br>\n",
    "- ```Architecture``` : Neuron과 Layer를 Initialization하고, Forward Propagation을 수행합니다.</br>\n",
    "- ```Cost function``` : Model과 Label간의 차이를 계산합니다. </br>\n",
    "- ```Optimization``` : Backward Propagation을 수행하고, weight와 bias로 구성된 Parameter를 Update합니다. </br>\n",
    "\n",
    "이 세 가지의 구성요소를 코드로 구현하는 것은 매우 복잡하고 지루한 과정이기 때문에, </br>\n",
    "자주 사용되는 method는 ```Tensorflow```나 ```PyTorch```와 같은 Library에서 제공되는 것을 사용하는 것이 일반적입니다. </br>\n",
    "</br>\n",
    "그러나 만약 Library를 사용하지 않고 CNNs를 구현한다면, 어떤 부분이 기존 Library에서 제공되었는지를 파악해야 합니다, </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cc644e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dd9645",
   "metadata": {},
   "source": [
    "# <font color=Red># Modulization </font>\n",
    "\n",
    "먼저, 신경망에 사용되는 여러 가지 함수들을 ```Module```화 하는 것이 중요합니다. </br>\n",
    "여기서 Module이란 여러 학문 분야에서 사용하는 용어인데, Computer Science에서 사용되는 경우 </br>\n",
    "특정 프로그램을 구성하는 기본 단위를 의미합니다. </br>\n",
    "</br>\n",
    "신경망을 구현하는 데 필요한 각종 Module들은 앞서 설명되었듯이, 여러 Library에서 제공되지만 </br>\n",
    "해당 프로젝트에서는 Torch 없이 Module들을 구현하는 것을 목표로 하므로, 어떤 Module이 사용되는지 먼저 살펴봅니다. </br>\n",
    "신경망에서 자주 사용되는 Module들에는 다음과 같은 것들이 있습니다. </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f98f541",
   "metadata": {},
   "source": [
    "### Convolution\n",
    "가장 먼저, 이미지의 각종 특징(Feature)들을 추출하는 ```Convolution``` 연산을 수행합니다.</br>\n",
    "Convolution은, ```Filter``` 혹은 ```Kernel```이라 불리는 Matrix를 원본 이미지에 곱함으로써 수행됩니다.</br>\n",
    "이때, Filter Size는 ```VGGNet```의 설정을 참고하여, 모든 레이어에서 3x3으로 고정합니다.\n",
    "\n",
    "**Ref:Very Deep Convolutional Networks for Large-Scale Image Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2753c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(input, filters, bias, stride=1, padding=1):\n",
    "    batch_size, in_channel, in_height, in_width = input.shape  # 입력 텐서의 형태 (배치 크기, 채널 수, 높이, 너비) 구함\n",
    "    out_channel, _, filter_height, filter_width = filters.shape  # 필터(커널)의 형태 (출력 채널 수, 입력 채널 수, 필터 높이, 필터 너비) 구함\n",
    "    \n",
    "    # 입력 텐서에 패딩 추가\n",
    "    padded_input = cp.pad(input, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    \n",
    "    # 출력 텐서의 높이와 너비 계산\n",
    "    out_height = (in_height - filter_height + 2 * padding) // stride + 1\n",
    "    out_width = (in_width - filter_width + 2 * padding) // stride + 1\n",
    "\n",
    "    # 출력 텐서 초기화 (배치 크기, 출력 채널 수, 출력 높이, 출력 너비)\n",
    "    output = cp.zeros((batch_size, out_channel, out_height, out_width))\n",
    "    \n",
    "    # 출력 텐서의 각 위치에 대해 계산\n",
    "    for i in range(out_height):\n",
    "        for j in range(out_width):\n",
    "            h_start = i * stride  # 입력 텐서에서 현재 위치의 시작 높이\n",
    "            h_end = h_start + filter_height  # 입력 텐서에서 현재 위치의 끝 높이\n",
    "            w_start = j * stride  # 입력 텐서에서 현재 위치의 시작 너비\n",
    "            w_end = w_start + filter_width  # 입력 텐서에서 현재 위치의 끝 너비\n",
    "            region = padded_input[:, :, h_start:h_end, w_start:w_end]  # 입력 텐서에서 현재 위치의 영역 추출\n",
    "\n",
    "            # 각 출력 채널에 대해 필터를 적용하여 값 계산\n",
    "            for k in range(out_channel):\n",
    "                output[:, k, i, j] = cp.sum(region * filters[k, :, :, :], axis=(1, 2, 3))\n",
    "    \n",
    "    # 바이어스를 출력에 더해줌\n",
    "    output += bias[None, :, None, None]\n",
    "    return output  # 최종 출력 텐서 반환\n",
    "\n",
    "\n",
    "def conv2d_backward(dout, input, filters, stride=1, padding=1):\n",
    "    batch_size, in_channel, in_height, in_width = input.shape  # 입력 텐서의 형태 구함\n",
    "    out_channel, _, filter_height, filter_width = filters.shape  # 필터(커널)의 형태 구함\n",
    "    _, _, out_height, out_width = dout.shape  # dout의 형태 (배치 크기, 출력 채널 수, 출력 높이, 출력 너비) 구함\n",
    "\n",
    "    # 입력 텐서에 패딩 추가\n",
    "    padded_input = cp.pad(input, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode='constant')\n",
    "    \n",
    "    # 역전파를 위한 초기화\n",
    "    dpadded_input = cp.zeros_like(padded_input)  # 패딩된 입력에 대한 변화도\n",
    "    dfilters = cp.zeros_like(filters)  # 필터에 대한 변화도\n",
    "    dbias = cp.sum(dout, axis=(0, 2, 3))  # 바이어스에 대한 변화도\n",
    "\n",
    "    # 각 위치에서 역전파 수행\n",
    "    for i in range(out_height):\n",
    "        for j in range(out_width):\n",
    "            h_start = i * stride  # 입력 텐서에서 현재 위치의 시작 높이\n",
    "            h_end = h_start + filter_height  # 입력 텐서에서 현재 위치의 끝 높이\n",
    "            w_start = j * stride  # 입력 텐서에서 현재 위치의 시작 너비\n",
    "            w_end = w_start + filter_width  # 입력 텐서에서 현재 위치의 끝 너비\n",
    "            region = padded_input[:, :, h_start:h_end, w_start:w_end]  # 입력 텐서에서 현재 위치의 영역 추출\n",
    "\n",
    "            # 각 출력 채널에 대해 역전파 수행\n",
    "            for k in range(out_channel):\n",
    "                dfilters[k, :, :, :] += cp.sum(region * dout[:, k:k+1, i:i+1, j:j+1], axis=0)  # 필터의 변화도 누적\n",
    "                dpadded_input[:, :, h_start:h_end, w_start:w_end] += filters[k, :, :, :] * dout[:, k:k+1, i:i+1, j:j+1]  # 패딩된 입력의 변화도 누적\n",
    "\n",
    "    # 패딩을 제거하여 입력에 대한 변화도 계산\n",
    "    dinput = dpadded_input[:, :, padding:-padding, padding:-padding] if padding else dpadded_input\n",
    "\n",
    "    return dinput, dfilters, dbias  # 입력, 필터, 바이어스에 대한 변화도 반환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08642505",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "해당 이미지의 특정 영역의 값을 압축하는 ```Pooling```연산을 수행합니다.</br>\n",
    "Classification Task에서는 다른 Pooling 방법에 비해 특정 영역을 해당 영역의 최댓값으로 압축하는 ```Max Polling```이 일반적으로 더 좋은 성능을 보여주므로,</br>\n",
    "해당 코드에서도 Max Pooling을 기본적으로 구현합니다.</br>\n",
    "Max Pooling 역시 Convolution과 동일하게 Pooling Kernel을 설정하지만 </br>\n",
    "Convoltuion과는 다르게 Parameter를 저장할 필요가 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0544e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool2d(input, pool_size=2, stride=2):\n",
    "    batch_size, channel, height, width = input.shape  # 입력 텐서의 형태 (배치 크기, 채널 수, 높이, 너비) 구함\n",
    "    out_height = (height - pool_size) // stride + 1  # 출력 텐서의 높이 계산\n",
    "    out_width = (width - pool_size) // stride + 1  # 출력 텐서의 너비 계산\n",
    "    output = cp.zeros((batch_size, channel, out_height, out_width))  # 출력 텐서 초기화\n",
    "    max_indices = cp.zeros_like(input)  # 최대값 인덱스 초기화\n",
    "\n",
    "    # 출력 텐서의 각 위치에 대해 최대 풀링 수행\n",
    "    for i in range(out_height):\n",
    "        for j in range(out_width):\n",
    "            h_start = i * stride  # 입력 텐서에서 현재 위치의 시작 높이\n",
    "            h_end = h_start + pool_size  # 입력 텐서에서 현재 위치의 끝 높이\n",
    "            w_start = j * stride  # 입력 텐서에서 현재 위치의 시작 너비\n",
    "            w_end = w_start + pool_size  # 입력 텐서에서 현재 위치의 끝 너비\n",
    "            region = input[:, :, h_start:h_end, w_start:w_end]  # 입력 텐서에서 현재 위치의 영역 추출\n",
    "            output[:, :, i, j] = cp.max(region, axis=(2, 3))  # 영역 내의 최대값 계산하여 출력 텐서에 저장\n",
    "            max_indices[:, :, h_start:h_end, w_start:w_end] += (region == output[:, :, i:i+1, j:j+1])  # 최대값 위치 저장\n",
    "\n",
    "    return output, max_indices  # 최대 풀링 결과와 최대값 인덱스 반환\n",
    "\n",
    "def max_pool2d_backward(dout, max_indices, pool_size=2, stride=2):\n",
    "    batch_size, channel, height, width = max_indices.shape  # 최대값 인덱스의 형태 (배치 크기, 채널 수, 높이, 너비) 구함\n",
    "    dinput = cp.zeros_like(max_indices)  # 입력에 대한 변화도 초기화\n",
    "\n",
    "    out_height = dout.shape[2]  # dout의 높이 구함\n",
    "    out_width = dout.shape[3]  # dout의 너비 구함\n",
    "\n",
    "    # 역전파 수행\n",
    "    for i in range(out_height):\n",
    "        for j in range(out_width):\n",
    "            h_start = i * stride  # 입력 텐서에서 현재 위치의 시작 높이\n",
    "            h_end = h_start + pool_size  # 입력 텐서에서 현재 위치의 끝 높이\n",
    "            w_start = j * stride  # 입력 텐서에서 현재 위치의 시작 너비\n",
    "            w_end = w_start + pool_size  # 입력 텐서에서 현재 위치의 끝 너비\n",
    "            dinput[:, :, h_start:h_end, w_start:w_end] += (max_indices[:, :, h_start:h_end, w_start:w_end] * dout[:, :, i:i+1, j:j+1])  # 최대값 위치에 dout 적용\n",
    "\n",
    "    return dinput  # 입력에 대한 변화도 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9969d489",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "- Sigmoid, ReLU, Softmax\n",
    "기본적으로 Activation Function으로는 ```ReLU```를 사용하고, </br>\n",
    "Classification Task를 수행하기 때문에</br>\n",
    "Classifier의 마지막 Layer에서는 ```Softmax```를 사용합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec581626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return cp.maximum(0, x)\n",
    "\n",
    "def relu_backward(dout, x):\n",
    "    return dout * (x > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39461ca",
   "metadata": {},
   "source": [
    "**Convolution과 Pooling으로 구성된 Feature Extractor의 설정은 다음과 같습니다.**\n",
    "\n",
    "|Layer|in_channel|out_chnnel|kernel_size|stride|padding|\n",
    "|---|---|---|---|---|---|\n",
    "|Conv1|1|32|3|1|1|\n",
    "|Conv2|32|32|3|1|1|\n",
    "|Pool1|2|2|0|\n",
    "|Conv3|32|128|1|1|1|\n",
    "|Conv4|128|128|3|1|1|\n",
    "|Pool2|2|2|0|\n",
    "|Conv5|128|256|3|1|1|\n",
    "|Conv6|256|256|3|1|1|\n",
    "|Pool3|2|2|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063088be",
   "metadata": {},
   "source": [
    "### Linear Combination(FC layer)\n",
    "Feature extractor에서 생성한 Feature의 정보를 모아서 분류를 수행하는 Classifier를 정의합니다. </br>\n",
    "Classifier에서는 Feature의 정보를 모으기 위해 Convolutional Layer를 Flatten(Vectorization)하기 때문에 </br>\n",
    "각 Neuron들을 ```Linear Combination```으로 연결하는 ```Fully Connected(FC) Layer```를 구현해야 합니다. </br>\n",
    "\n",
    "**Classifier의 설정은 다음과 같습니다.**\n",
    "\n",
    "|Layer|in_features|out_features|\n",
    "|---|---|---|\n",
    "|FC1|3x3x256|4096|\n",
    "|Dropout(0.5)|\n",
    "|FC2|4096|10|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9bb65d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(input):\n",
    "    return input.reshape(input.shape[0], -1)  # 입력 텐서를 평탄화하여 2차원 텐서로 변환 (배치 크기, 나머지 차원)\n",
    "\n",
    "def fully_connected(input, weights, bias):\n",
    "    return cp.dot(input, weights) + bias  # 입력 텐서와 가중치를 행렬 곱셈하고 바이어스를 더하여 선형 변환 수행\n",
    "\n",
    "def fully_connected_backward(dout, input, weights):\n",
    "    dinput = cp.dot(dout, weights.T)  # dout과 가중치의 전치를 곱하여 입력에 대한 변화도 계산\n",
    "    dweights = cp.dot(input.T, dout)  # 입력의 전치와 dout을 곱하여 가중치에 대한 변화도 계산\n",
    "    dbias = cp.sum(dout, axis=0)  # dout의 모든 배치에 대해 합을 구하여 바이어스에 대한 변화도 계산\n",
    "    return dinput, dweights, dbias  # 입력, 가중치, 바이어스에 대한 변화도 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f268a",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "더 이상의 자세한 설명은 생략한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2568c881",
   "metadata": {},
   "source": [
    "# <font color=Red># Class </font>\n",
    "\n",
    "Python에서는 Class를 이용하여 Modulization을 수행할 수 있습니다. </br>\n",
    "이때, 중요한 점은 해당 Class의 method는, 각 module의 ```Forward Propagation``` 부분과</br> \n",
    "```Backpropagation```이 모두 구현되어 있어야 한다는 점입니다.</br>\n",
    "\n",
    "따라서, 모든 클래스에는 Forward Propagation method에서 해당 함수의 연산을 수행하는 부분을 정의하고, </br>\n",
    "Backpropagation method에서 해당 함수의 ```gradient```를 계산하는 연산을 수행하는 부분을 정의합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82edec98",
   "metadata": {},
   "source": [
    "### Dropout Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c829fa",
   "metadata": {},
   "source": [
    "#### Forward Propagation\n",
    "define p : dropout probability </br>\n",
    "\n",
    "$$\\text{mask} = \\frac{\\mathbf{r}}{1-p}$$\n",
    "r = uniformly distributed matrix for range [0, 1]\n",
    "\n",
    "- **During Training**\n",
    "$$\\mathbf{y} = \\mathbf{x} \\odot \\text{mask}$$\n",
    "여기서, $\\mathbf{y}$는 Dropout이 적용된 출력, $\\mathbf{x}$는 입력, $\\odot$는 element-wise multiplication을 나타냄.\n",
    "\n",
    "- **During Test**\n",
    "$$\\mathbf{y} = \\mathbf{x}$$\n",
    "Test 시에는 Dropout이 적용되지 않음.\n",
    "\n",
    "#### Backward Propagation\n",
    "$$\\mathbf{dout} = \\mathbf{dout} \\odot \\text{mask}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22390148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p  # 드롭아웃 확률 설정\n",
    "        self.mask = None  # 마스크 초기화\n",
    "\n",
    "    def forward(self, input, train=True):\n",
    "        if train:  # 학습 중일 때\n",
    "            self.mask = (cp.random.rand(*input.shape) > self.p) / (1 - self.p)  # 드롭아웃 마스크 생성\n",
    "            return input * self.mask  # 입력에 마스크 적용하여 드롭아웃 수행\n",
    "        else:  # 평가 중일 때\n",
    "            return input  # 입력 그대로 반환\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask  # 역전파 시 마스크 적용하여 그래디언트 계산\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e6b30",
   "metadata": {},
   "source": [
    "### Convolution Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be3d6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=1):\n",
    "        self.stride = stride  # 스트라이드 값 설정\n",
    "        self.padding = padding  # 패딩 값 설정\n",
    "        # He 초기화를 사용하여 필터 가중치 초기화\n",
    "        self.weights = cp.random.randn(out_channels, in_channels, kernel_size, kernel_size) * cp.sqrt(2 / (in_channels * kernel_size * kernel_size))\n",
    "        self.bias = cp.random.randn(out_channels)  # 바이어스 초기화\n",
    "        self.dweights = cp.zeros_like(self.weights)  # 필터 가중치 변화도 초기화\n",
    "        self.dbias = cp.zeros_like(self.bias)  # 바이어스 변화도 초기화\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input  # 입력값 저장 (역전파를 위해)\n",
    "        # 컨벌루션 연산 수행 후 ReLU 활성화 함수 적용하여 출력 계산\n",
    "        self.output = relu(conv2d(input, self.weights, self.bias, self.stride, self.padding))\n",
    "        return self.output  # 최종 출력 반환\n",
    "\n",
    "    def backward(self, dout):\n",
    "        # ReLU의 역전파 수행\n",
    "        dout = relu_backward(dout, self.output)\n",
    "        # 컨벌루션 연산의 역전파 수행하여 입력, 필터 가중치, 바이어스에 대한 변화도 계산\n",
    "        dinput, self.dweights, self.dbias = conv2d_backward(dout, self.input, self.weights, self.stride, self.padding)\n",
    "        return dinput  # 입력에 대한 변화도 반환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5312ec54",
   "metadata": {},
   "source": [
    "### Maxpool Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf758ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    def __init__(self, pool_size=2, stride=2):\n",
    "        self.pool_size = pool_size  # 풀링 크기 설정\n",
    "        self.stride = stride  # 스트라이드 값 설정\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input  # 입력값 저장 (역전파를 위해)\n",
    "        # 최대 풀링 연산 수행, 출력값과 최대값 인덱스 저장\n",
    "        self.output, self.max_indices = max_pool2d(input, self.pool_size, self.stride)\n",
    "        return self.output  # 최종 출력 반환\n",
    "\n",
    "    def backward(self, dout):\n",
    "        # 최대 풀링의 역전파 수행하여 입력에 대한 변화도 계산\n",
    "        return max_pool2d_backward(dout, self.max_indices, self.pool_size, self.stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3527757b",
   "metadata": {},
   "source": [
    "### ReLU Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f424f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    @staticmethod\n",
    "    def forward(x):\n",
    "        return relu(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(dout, x):\n",
    "        return relu_backward(dout, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a47dd",
   "metadata": {},
   "source": [
    "### Vectorization Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67d03031",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def forward(self, input):\n",
    "        self.input_shape = input.shape\n",
    "        output = flatten(input)\n",
    "        return output\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout.reshape(self.input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1c7c7e",
   "metadata": {},
   "source": [
    "### Linear Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57a4b9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnected:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        # He initialization을 사용하여 가중치 초기화\n",
    "        self.weights = cp.random.randn(in_features, out_features) * cp.sqrt(2 / in_features)\n",
    "        self.bias = cp.random.randn(out_features)  # 바이어스 초기화\n",
    "        self.dweights = cp.zeros_like(self.weights)  # 가중치 변화도 초기화\n",
    "        self.dbias = cp.zeros_like(self.bias)  # 바이어스 변화도 초기화\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input  # 입력값 저장 (역전파를 위해)\n",
    "        self.output = fully_connected(input, self.weights, self.bias)  # 선형 변환 수행\n",
    "        return relu(self.output)  # ReLU 활성화 함수 적용 후 반환\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = relu_backward(dout, self.output)  # ReLU의 역전파 수행\n",
    "        # 선형 변환의 역전파 수행하여 입력, 가중치, 바이어스에 대한 변화도 계산\n",
    "        dinput, self.dweights, self.dbias = fully_connected_backward(dout, self.input, self.weights)\n",
    "        return dinput  # 입력에 대한 변화도 반환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f13513",
   "metadata": {},
   "source": [
    "### MC Dropout for ESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10c6b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict(test_batches, model, num_samples=10):\n",
    "    predictions = []  # 예측값을 저장할 리스트 초기화\n",
    "\n",
    "    for _ in range(num_samples):  # 지정된 샘플 수만큼 반복\n",
    "        batch_predictions = []  # 각 배치에 대한 예측값을 저장할 리스트 초기화\n",
    "        for input, _ in test_batches:  # 테스트 배치 반복\n",
    "            output = model.forward(input, train=True)  # Dropout을 활성화된 상태로 추론\n",
    "            batch_predictions.append(cp.expand_dims(cp.argmax(output, axis=1), axis=0))  # 예측값을 차원 확장하여 리스트에 추가\n",
    "        predictions.append(cp.concatenate(batch_predictions, axis=0))  # 배치별 예측값을 연결하여 리스트에 추가\n",
    "\n",
    "    predictions = cp.stack(predictions, axis=0)  # 예측값을 스택하여 [num_samples, num_batches, batch_size] 형태로 만듦\n",
    "    mean_predictions = cp.mean(predictions, axis=0)  # 각 배치에 대해 예측값의 평균 계산\n",
    "    final_predictions = cp.argmax(mean_predictions, axis=1)  # 평균 예측값에서 가장 높은 확률을 가진 클래스 선택\n",
    "    \n",
    "    return final_predictions  # 최종 예측값 반환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89a7be2",
   "metadata": {},
   "source": [
    "# <font color=Red># Architecture </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac09d902",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN:\n",
    "    def __init__(self):\n",
    "        self.layers = [\n",
    "            Conv2D(1, 32, 3, stride=1, padding=1), # 28 x 28\n",
    "            Conv2D(32, 32, 3, stride=1, padding=1), # 28 x 28\n",
    "            MaxPool2D(2, 2), # 14 x 14\n",
    "            Conv2D(32, 128, 3, stride=1, padding=1), # 14 x 14\n",
    "            Conv2D(128, 128, 3, stride=1, padding=1), # 14 x 14\n",
    "            MaxPool2D(2, 2), # 7 x 7\n",
    "            Conv2D(128, 256, 3, stride=1, padding=1), # 7 x 7\n",
    "            Conv2D(256, 256, 3, stride=1, padding=1), # 7 x 7\n",
    "            MaxPool2D(2, 2), # 3 x 3\n",
    "            Flatten(),  \n",
    "            FullyConnected(256 * 3 * 3, 4096),  \n",
    "            Dropout(0.5),  \n",
    "            FullyConnected(4096, 128),  \n",
    "            Dropout(0.5),  \n",
    "            FullyConnected(128, 10)  \n",
    "        ]\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "#             print(f\"Layer {layer.__class__.__name__} output shape: {x.shape}\")\n",
    "        return x\n",
    "\n",
    "    def backward(self, dout):\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    def get_params(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Conv2D) or isinstance(layer, FullyConnected):\n",
    "                params.append({'value': layer.weights, 'grad': layer.dweights})\n",
    "                params.append({'value': layer.bias, 'grad': layer.dbias})\n",
    "        return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d3d4e8",
   "metadata": {},
   "source": [
    "# <font color=Red># Cost Function </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acc6f284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(output, target):\n",
    "    batch_size = target.shape[0]\n",
    "    output = cp.clip(output, 1e-12, 1. - 1e-12)\n",
    "    loss = -cp.sum(target * cp.log(output)) / batch_size\n",
    "    return loss\n",
    "\n",
    "def cross_entropy_derivative(output, target):\n",
    "    return output - target\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0ca602",
   "metadata": {},
   "source": [
    "# <font color=Red># Data Loader </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d182a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=32, train_samples=2000, test_samples=500):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_data = train_dataset.data.numpy()\n",
    "    train_labels = train_dataset.targets.numpy()\n",
    "    test_data = test_dataset.data.numpy()\n",
    "    test_labels = test_dataset.targets.numpy()\n",
    "\n",
    "    train_data = train_data / 255.0\n",
    "    test_data = test_data / 255.0\n",
    "\n",
    "    train_data = np.expand_dims(train_data, axis=1)\n",
    "    test_data = np.expand_dims(test_data, axis=1)\n",
    "\n",
    "    train_data = (train_data - 0.5) / 0.5\n",
    "    test_data = (test_data - 0.5) / 0.5\n",
    "\n",
    "    \n",
    "    train_indices = np.random.choice(len(train_data), train_samples, replace=False)\n",
    "    test_indices = np.random.choice(len(test_data), test_samples, replace=False)\n",
    "\n",
    "    sampled_train_data = train_data[train_indices]\n",
    "    sampled_train_labels = train_labels[train_indices]\n",
    "    sampled_test_data = test_data[test_indices]\n",
    "    sampled_test_labels = test_labels[test_indices]\n",
    "\n",
    "    def create_batches(data, labels, batch_size):\n",
    "        for start in range(0, len(data), batch_size):\n",
    "            end = start + batch_size\n",
    "            batch_data = cp.asarray(data[start:end])\n",
    "            batch_labels = cp.asarray(labels[start:end])\n",
    "            \n",
    "            yield batch_data, batch_labels\n",
    "\n",
    "    train_batches = list(create_batches(sampled_train_data, sampled_train_labels, batch_size))\n",
    "    test_batches = list(create_batches(sampled_test_data, sampled_test_labels, batch_size))\n",
    "\n",
    "    return train_batches, test_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b30000",
   "metadata": {},
   "source": [
    "# <font color=Red># Optimization </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a958a",
   "metadata": {},
   "source": [
    "### ADAM(Adaptive Moment Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bceff89",
   "metadata": {},
   "source": [
    "**0. Initialize 1st momentum and 2nd momentum**\n",
    "$$m_0 = 0 $$ \n",
    "$$v_0 = 0 $$ </br>\n",
    "\n",
    "**1. Update Time step** </br>\n",
    "$$t = t + 1$$\n",
    "\n",
    "\n",
    "**2. Update 1st Momentum and 2nd Momentum(using the gradient g)**\n",
    "\n",
    "$$m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot g_t$$\n",
    "$$v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot g_t^2$$\n",
    "\n",
    "**3. Update estimation**\n",
    "$$\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}$$\n",
    "$$\\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$$\n",
    "\n",
    "**4. Update parameters(w, b)**\n",
    "\n",
    "$$theta_t = \\theta_{t-1} - \\alpha \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$$\n",
    "\n",
    "- Momentum coefficient(Friction)$(\\beta_1,\\,\\,\\beta_2)$ , Generally choosen 0.9 and 0.999, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae087ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, params, lr=1e-5, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.params = params  # w, b (parameters to optimize)\n",
    "        self.lr = lr  # Learning rate\n",
    "        self.beta1 = beta1  # coefficient of 1st momentum\n",
    "        self.beta2 = beta2  # coefficient of 2nd momentum\n",
    "        self.epsilon = epsilon  # avoid to devided by 0\n",
    "        \n",
    "        self.m = [cp.zeros_like(p['value']) for p in params]  # initialize 1st momentum\n",
    "        self.v = [cp.zeros_like(p['value']) for p in params]  # initialize 2nd momentum\n",
    "        self.t = 0  # initialize time step\n",
    "\n",
    "    def step(self):\n",
    "        self.t += 1  # 타임스텝 증가\n",
    "        for i, param in enumerate(self.params):  # For each parameters\n",
    "            grad = param['grad']  # Gradient of the parameters(w, b)\n",
    "            # Update 1st momentum\n",
    "            self.m[i] = self.beta1 * self.m[i] + (1 - self.beta1) * grad\n",
    "            # Update 2nd momentum\n",
    "            self.v[i] = self.beta2 * self.v[i] + (1 - self.beta2) * (grad ** 2)\n",
    "            # update 1st momentum estimation\n",
    "            m_hat = self.m[i] / (1 - self.beta1 ** self.t)\n",
    "            # update 2nd momentum estimation \n",
    "            v_hat = self.v[i] / (1 - self.beta2 ** self.t)\n",
    "            # update parameters\n",
    "            param['value'] -= self.lr * m_hat / (cp.sqrt(v_hat) + self.epsilon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7e02585",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(train_batches, model, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for i, (input, target) in enumerate(train_batches):\n",
    "            # Forward pass\n",
    "            output = model.forward(input)\n",
    "            # Compute loss\n",
    "            output = softmax(output)\n",
    "            loss = cross_entropy_loss(output, target)\n",
    "            total_loss += loss\n",
    "            # Backward pass\n",
    "            dout = cross_entropy_derivative(output, target)\n",
    "            model.backward(dout)\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "#             print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {loss}')\n",
    "            print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {loss}, Batch Size: {input.shape[0]}')\n",
    "        print(f'Epoch {epoch + 1}, Average Loss: {total_loss / len(train_batches)}')\n",
    "\n",
    "def test(test_batches, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for input, target in test_batches:\n",
    "        output = model.forward(input)\n",
    "        output = softmax(output)\n",
    "        predictions = cp.argmax(output, axis=1)\n",
    "        labels = cp.argmax(target, axis=1)\n",
    "        correct += cp.sum(predictions == labels)\n",
    "        total += labels.size\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28490167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mc(test_batches, model, num_samples=10):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for input, target in test_batches:\n",
    "        output = mc_dropout_predict([(input, target)], model, num_samples=num_samples)\n",
    "        labels = cp.argmax(target, axis=1)\n",
    "        correct += cp.sum(output == labels)\n",
    "        total += labels.size\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0353f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, num_classes=10):\n",
    "    return cp.eye(num_classes)[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5cd6553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Load data\n",
    "train_batches, test_batches = load_data()\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "train_batches = [(data, to_one_hot(labels)) for data, labels in train_batches]\n",
    "test_batches = [(data, to_one_hot(labels)) for data, labels in test_batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411c104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 1, Loss: 8.945937896198348, Batch Size: 32\n",
      "Epoch 1, Batch 2, Loss: 9.372462881177787, Batch Size: 32\n",
      "Epoch 1, Batch 3, Loss: 7.8541191926773575, Batch Size: 32\n",
      "Epoch 1, Batch 4, Loss: 8.993198310464228, Batch Size: 32\n",
      "Epoch 1, Batch 5, Loss: 8.773692264104056, Batch Size: 32\n",
      "Epoch 1, Batch 6, Loss: 8.43431199048783, Batch Size: 32\n",
      "Epoch 1, Batch 7, Loss: 6.84116654431034, Batch Size: 32\n",
      "Epoch 1, Batch 8, Loss: 9.11850859569022, Batch Size: 32\n",
      "Epoch 1, Batch 9, Loss: 8.583800705422357, Batch Size: 32\n",
      "Epoch 1, Batch 10, Loss: 8.294407962411455, Batch Size: 32\n",
      "Epoch 1, Batch 11, Loss: 9.384853586680766, Batch Size: 32\n",
      "Epoch 1, Batch 12, Loss: 8.707110608327126, Batch Size: 32\n",
      "Epoch 1, Batch 13, Loss: 8.999608019940176, Batch Size: 32\n",
      "Epoch 1, Batch 14, Loss: 9.044055866616286, Batch Size: 32\n",
      "Epoch 1, Batch 15, Loss: 8.469025550108455, Batch Size: 32\n",
      "Epoch 1, Batch 16, Loss: 7.9052636195561075, Batch Size: 32\n",
      "Epoch 1, Batch 17, Loss: 8.793357694355118, Batch Size: 32\n",
      "Epoch 1, Batch 18, Loss: 8.31412172813084, Batch Size: 32\n",
      "Epoch 1, Batch 19, Loss: 9.023380710217152, Batch Size: 32\n",
      "Epoch 1, Batch 20, Loss: 7.980455076030293, Batch Size: 32\n",
      "Epoch 1, Batch 21, Loss: 8.611740482192726, Batch Size: 32\n",
      "Epoch 1, Batch 22, Loss: 7.62110444923883, Batch Size: 32\n",
      "Epoch 1, Batch 23, Loss: 8.752959231737936, Batch Size: 32\n",
      "Epoch 1, Batch 24, Loss: 8.892258568022097, Batch Size: 32\n",
      "Epoch 1, Batch 25, Loss: 9.522409211867242, Batch Size: 32\n",
      "Epoch 1, Batch 26, Loss: 8.020364518587874, Batch Size: 32\n",
      "Epoch 1, Batch 27, Loss: 8.982612201916096, Batch Size: 32\n",
      "Epoch 1, Batch 28, Loss: 8.676520345870841, Batch Size: 32\n",
      "Epoch 1, Batch 29, Loss: 8.906928419643481, Batch Size: 32\n",
      "Epoch 1, Batch 30, Loss: 7.713851357367709, Batch Size: 32\n",
      "Epoch 1, Batch 31, Loss: 7.373848594225334, Batch Size: 32\n",
      "Epoch 1, Batch 32, Loss: 6.843192822312125, Batch Size: 32\n",
      "Epoch 1, Batch 33, Loss: 8.159882386383929, Batch Size: 32\n",
      "Epoch 1, Batch 34, Loss: 7.979294812944628, Batch Size: 32\n",
      "Epoch 1, Batch 35, Loss: 8.242199911322048, Batch Size: 32\n",
      "Epoch 1, Batch 36, Loss: 7.088786499758458, Batch Size: 32\n",
      "Epoch 1, Batch 37, Loss: 8.99071798112233, Batch Size: 32\n",
      "Epoch 1, Batch 38, Loss: 9.940753204094072, Batch Size: 32\n",
      "Epoch 1, Batch 39, Loss: 9.589556657455336, Batch Size: 32\n",
      "Epoch 1, Batch 40, Loss: 7.156047216711756, Batch Size: 32\n",
      "Epoch 1, Batch 41, Loss: 8.827607413589034, Batch Size: 32\n",
      "Epoch 1, Batch 42, Loss: 8.87070767946546, Batch Size: 32\n",
      "Epoch 1, Batch 43, Loss: 8.100432772698051, Batch Size: 32\n",
      "Epoch 1, Batch 44, Loss: 7.584752212088967, Batch Size: 32\n",
      "Epoch 1, Batch 45, Loss: 9.043868054714638, Batch Size: 32\n",
      "Epoch 1, Batch 46, Loss: 8.234556314049106, Batch Size: 32\n",
      "Epoch 1, Batch 47, Loss: 8.124755572782146, Batch Size: 32\n",
      "Epoch 1, Batch 48, Loss: 10.433644312202048, Batch Size: 32\n",
      "Epoch 1, Batch 49, Loss: 9.056570944516098, Batch Size: 32\n",
      "Epoch 1, Batch 50, Loss: 8.810191975096462, Batch Size: 32\n",
      "Epoch 1, Batch 51, Loss: 10.655650320122042, Batch Size: 32\n",
      "Epoch 1, Batch 52, Loss: 9.061495102318545, Batch Size: 32\n",
      "Epoch 1, Batch 53, Loss: 8.822646748848062, Batch Size: 32\n",
      "Epoch 1, Batch 54, Loss: 8.861410485430056, Batch Size: 32\n",
      "Epoch 1, Batch 55, Loss: 8.976096300061368, Batch Size: 32\n",
      "Epoch 1, Batch 56, Loss: 8.508021391451345, Batch Size: 32\n",
      "Epoch 1, Batch 57, Loss: 7.984109797676483, Batch Size: 32\n",
      "Epoch 1, Batch 58, Loss: 9.513628557610064, Batch Size: 32\n",
      "Epoch 1, Batch 59, Loss: 8.15382551464454, Batch Size: 32\n",
      "Epoch 1, Batch 60, Loss: 7.461091502410941, Batch Size: 32\n",
      "Epoch 1, Batch 61, Loss: 6.880824525851712, Batch Size: 32\n",
      "Epoch 1, Batch 62, Loss: 9.350940010291469, Batch Size: 32\n",
      "Epoch 1, Batch 63, Loss: 8.275401720679545, Batch Size: 16\n",
      "Epoch 1, Average Loss: 8.54746185562348\n",
      "Epoch 2, Batch 1, Loss: 8.99809669845149, Batch Size: 32\n",
      "Epoch 2, Batch 2, Loss: 7.582979767644948, Batch Size: 32\n",
      "Epoch 2, Batch 3, Loss: 8.37357881594111, Batch Size: 32\n",
      "Epoch 2, Batch 4, Loss: 9.628739921900443, Batch Size: 32\n",
      "Epoch 2, Batch 5, Loss: 8.819471964295511, Batch Size: 32\n",
      "Epoch 2, Batch 6, Loss: 8.038615442172372, Batch Size: 32\n",
      "Epoch 2, Batch 7, Loss: 10.32461784839379, Batch Size: 32\n",
      "Epoch 2, Batch 8, Loss: 8.232341670028436, Batch Size: 32\n",
      "Epoch 2, Batch 9, Loss: 8.624491828492475, Batch Size: 32\n",
      "Epoch 2, Batch 10, Loss: 9.498577359085356, Batch Size: 32\n",
      "Epoch 2, Batch 11, Loss: 8.059724025875008, Batch Size: 32\n",
      "Epoch 2, Batch 12, Loss: 8.647705105868653, Batch Size: 32\n",
      "Epoch 2, Batch 13, Loss: 7.63219076691316, Batch Size: 32\n",
      "Epoch 2, Batch 14, Loss: 9.053987045175983, Batch Size: 32\n",
      "Epoch 2, Batch 15, Loss: 8.001468714849903, Batch Size: 32\n",
      "Epoch 2, Batch 16, Loss: 8.27002596096582, Batch Size: 32\n",
      "Epoch 2, Batch 17, Loss: 7.894522129525039, Batch Size: 32\n",
      "Epoch 2, Batch 18, Loss: 6.647073770586544, Batch Size: 32\n",
      "Epoch 2, Batch 19, Loss: 9.98983078976094, Batch Size: 32\n",
      "Epoch 2, Batch 20, Loss: 7.893027500083021, Batch Size: 32\n",
      "Epoch 2, Batch 21, Loss: 8.817304597077774, Batch Size: 32\n",
      "Epoch 2, Batch 22, Loss: 7.995788709207936, Batch Size: 32\n",
      "Epoch 2, Batch 23, Loss: 8.843122012785786, Batch Size: 32\n",
      "Epoch 2, Batch 24, Loss: 9.529192042266356, Batch Size: 32\n",
      "Epoch 2, Batch 25, Loss: 8.7211410756432, Batch Size: 32\n",
      "Epoch 2, Batch 26, Loss: 7.514133807367956, Batch Size: 32\n",
      "Epoch 2, Batch 27, Loss: 8.55097230113596, Batch Size: 32\n",
      "Epoch 2, Batch 28, Loss: 9.17887161880284, Batch Size: 32\n",
      "Epoch 2, Batch 29, Loss: 8.563900567606613, Batch Size: 32\n",
      "Epoch 2, Batch 30, Loss: 8.006479465442881, Batch Size: 32\n",
      "Epoch 2, Batch 31, Loss: 7.761967304263698, Batch Size: 32\n",
      "Epoch 2, Batch 32, Loss: 8.574401055620147, Batch Size: 32\n",
      "Epoch 2, Batch 33, Loss: 9.636511237626827, Batch Size: 32\n",
      "Epoch 2, Batch 34, Loss: 9.690709977728918, Batch Size: 32\n",
      "Epoch 2, Batch 35, Loss: 9.08768350191033, Batch Size: 32\n",
      "Epoch 2, Batch 36, Loss: 8.088438046057355, Batch Size: 32\n",
      "Epoch 2, Batch 37, Loss: 8.513048512016878, Batch Size: 32\n",
      "Epoch 2, Batch 38, Loss: 8.503104881148259, Batch Size: 32\n",
      "Epoch 2, Batch 39, Loss: 7.827439610908377, Batch Size: 32\n",
      "Epoch 2, Batch 40, Loss: 9.235392892459295, Batch Size: 32\n",
      "Epoch 2, Batch 41, Loss: 8.236395842265482, Batch Size: 32\n",
      "Epoch 2, Batch 42, Loss: 10.044405600805401, Batch Size: 32\n",
      "Epoch 2, Batch 43, Loss: 8.23733592068452, Batch Size: 32\n",
      "Epoch 2, Batch 44, Loss: 9.143842791622829, Batch Size: 32\n",
      "Epoch 2, Batch 45, Loss: 9.020319361817307, Batch Size: 32\n",
      "Epoch 2, Batch 46, Loss: 7.569742017693672, Batch Size: 32\n",
      "Epoch 2, Batch 47, Loss: 7.002881958186858, Batch Size: 32\n",
      "Epoch 2, Batch 48, Loss: 9.901878167127858, Batch Size: 32\n",
      "Epoch 2, Batch 49, Loss: 8.941649648990825, Batch Size: 32\n",
      "Epoch 2, Batch 50, Loss: 6.266453168423194, Batch Size: 32\n",
      "Epoch 2, Batch 51, Loss: 9.269972733931269, Batch Size: 32\n",
      "Epoch 2, Batch 52, Loss: 10.32725311128404, Batch Size: 32\n",
      "Epoch 2, Batch 53, Loss: 7.756799993046274, Batch Size: 32\n",
      "Epoch 2, Batch 54, Loss: 8.049349097744138, Batch Size: 32\n",
      "Epoch 2, Batch 55, Loss: 8.166419700240002, Batch Size: 32\n",
      "Epoch 2, Batch 56, Loss: 8.035636991665502, Batch Size: 32\n",
      "Epoch 2, Batch 57, Loss: 6.772245742782371, Batch Size: 32\n",
      "Epoch 2, Batch 58, Loss: 8.409318897043118, Batch Size: 32\n",
      "Epoch 2, Batch 59, Loss: 8.946138853615567, Batch Size: 32\n",
      "Epoch 2, Batch 60, Loss: 7.835984018843754, Batch Size: 32\n",
      "Epoch 2, Batch 61, Loss: 7.895111890806061, Batch Size: 32\n",
      "Epoch 2, Batch 62, Loss: 7.895217086304048, Batch Size: 32\n",
      "Epoch 2, Batch 63, Loss: 8.512652522508382, Batch Size: 16\n",
      "Epoch 2, Average Loss: 8.49345516604\n",
      "Epoch 3, Batch 1, Loss: 9.699136769419335, Batch Size: 32\n",
      "Epoch 3, Batch 2, Loss: 8.277230074490557, Batch Size: 32\n",
      "Epoch 3, Batch 3, Loss: 8.513278181494483, Batch Size: 32\n",
      "Epoch 3, Batch 4, Loss: 9.437386189814642, Batch Size: 32\n",
      "Epoch 3, Batch 5, Loss: 7.18860260057741, Batch Size: 32\n",
      "Epoch 3, Batch 6, Loss: 9.67164104077823, Batch Size: 32\n",
      "Epoch 3, Batch 7, Loss: 9.062680363357853, Batch Size: 32\n",
      "Epoch 3, Batch 8, Loss: 8.23362446793421, Batch Size: 32\n",
      "Epoch 3, Batch 9, Loss: 7.462661004871142, Batch Size: 32\n",
      "Epoch 3, Batch 10, Loss: 6.378318633550063, Batch Size: 32\n",
      "Epoch 3, Batch 11, Loss: 9.451561685431148, Batch Size: 32\n",
      "Epoch 3, Batch 12, Loss: 8.381482582832211, Batch Size: 32\n",
      "Epoch 3, Batch 13, Loss: 10.220147698709305, Batch Size: 32\n",
      "Epoch 3, Batch 14, Loss: 9.008190659153842, Batch Size: 32\n",
      "Epoch 3, Batch 15, Loss: 7.656487528357734, Batch Size: 32\n",
      "Epoch 3, Batch 16, Loss: 8.002925487538828, Batch Size: 32\n",
      "Epoch 3, Batch 17, Loss: 6.487006773322039, Batch Size: 32\n",
      "Epoch 3, Batch 18, Loss: 7.826704042264653, Batch Size: 32\n",
      "Epoch 3, Batch 19, Loss: 8.841304860712857, Batch Size: 32\n",
      "Epoch 3, Batch 20, Loss: 7.995672334017776, Batch Size: 32\n",
      "Epoch 3, Batch 21, Loss: 8.633068105283312, Batch Size: 32\n",
      "Epoch 3, Batch 22, Loss: 9.257614112507532, Batch Size: 32\n",
      "Epoch 3, Batch 23, Loss: 9.091247822965672, Batch Size: 32\n",
      "Epoch 3, Batch 24, Loss: 9.144400582584742, Batch Size: 32\n",
      "Epoch 3, Batch 25, Loss: 6.777546309131776, Batch Size: 32\n",
      "Epoch 3, Batch 26, Loss: 8.150386689757946, Batch Size: 32\n",
      "Epoch 3, Batch 27, Loss: 8.223246330895737, Batch Size: 32\n",
      "Epoch 3, Batch 28, Loss: 8.116720195662381, Batch Size: 32\n",
      "Epoch 3, Batch 29, Loss: 8.359442690874559, Batch Size: 32\n",
      "Epoch 3, Batch 30, Loss: 7.84314134675286, Batch Size: 32\n",
      "Epoch 3, Batch 31, Loss: 8.690635874031212, Batch Size: 32\n",
      "Epoch 3, Batch 32, Loss: 9.360354370074871, Batch Size: 32\n",
      "Epoch 3, Batch 33, Loss: 9.556565704897444, Batch Size: 32\n",
      "Epoch 3, Batch 34, Loss: 7.40208470484113, Batch Size: 32\n",
      "Epoch 3, Batch 35, Loss: 8.965999532148638, Batch Size: 32\n",
      "Epoch 3, Batch 36, Loss: 6.7934525210921555, Batch Size: 32\n",
      "Epoch 3, Batch 37, Loss: 9.065327336186362, Batch Size: 32\n",
      "Epoch 3, Batch 38, Loss: 10.209825336348706, Batch Size: 32\n",
      "Epoch 3, Batch 39, Loss: 7.83239020144241, Batch Size: 32\n",
      "Epoch 3, Batch 40, Loss: 9.873453364958198, Batch Size: 32\n",
      "Epoch 3, Batch 41, Loss: 7.318199982142773, Batch Size: 32\n",
      "Epoch 3, Batch 42, Loss: 8.986153852376223, Batch Size: 32\n",
      "Epoch 3, Batch 43, Loss: 8.302565976834986, Batch Size: 32\n",
      "Epoch 3, Batch 44, Loss: 10.550661411410909, Batch Size: 32\n",
      "Epoch 3, Batch 45, Loss: 8.813582711212073, Batch Size: 32\n",
      "Epoch 3, Batch 46, Loss: 9.70868453211646, Batch Size: 32\n",
      "Epoch 3, Batch 47, Loss: 9.307408055933662, Batch Size: 32\n",
      "Epoch 3, Batch 48, Loss: 8.219733754348223, Batch Size: 32\n",
      "Epoch 3, Batch 49, Loss: 7.07738238165535, Batch Size: 32\n",
      "Epoch 3, Batch 50, Loss: 7.797358032926374, Batch Size: 32\n",
      "Epoch 3, Batch 51, Loss: 9.661062471168961, Batch Size: 32\n",
      "Epoch 3, Batch 52, Loss: 7.7691788733783, Batch Size: 32\n",
      "Epoch 3, Batch 53, Loss: 8.42013308631004, Batch Size: 32\n",
      "Epoch 3, Batch 54, Loss: 8.023549960315425, Batch Size: 32\n",
      "Epoch 3, Batch 55, Loss: 7.794654633107231, Batch Size: 32\n",
      "Epoch 3, Batch 56, Loss: 9.68626388799416, Batch Size: 32\n",
      "Epoch 3, Batch 57, Loss: 9.605480492639169, Batch Size: 32\n",
      "Epoch 3, Batch 58, Loss: 10.157758619176999, Batch Size: 32\n",
      "Epoch 3, Batch 59, Loss: 9.755250615256568, Batch Size: 32\n",
      "Epoch 3, Batch 60, Loss: 7.587086986758523, Batch Size: 32\n",
      "Epoch 3, Batch 61, Loss: 8.019910587748523, Batch Size: 32\n",
      "Epoch 3, Batch 62, Loss: 7.516451487402081, Batch Size: 32\n",
      "Epoch 3, Batch 63, Loss: 10.146983753310735, Batch Size: 16\n",
      "Epoch 3, Average Loss: 8.561403845342696\n",
      "Epoch 4, Batch 1, Loss: 9.422294533338128, Batch Size: 32\n",
      "Epoch 4, Batch 2, Loss: 8.35352606375612, Batch Size: 32\n",
      "Epoch 4, Batch 3, Loss: 8.394618563358296, Batch Size: 32\n",
      "Epoch 4, Batch 4, Loss: 7.85871709717473, Batch Size: 32\n",
      "Epoch 4, Batch 5, Loss: 9.062881988884204, Batch Size: 32\n",
      "Epoch 4, Batch 6, Loss: 7.015429870901951, Batch Size: 32\n",
      "Epoch 4, Batch 7, Loss: 8.29495367562321, Batch Size: 32\n",
      "Epoch 4, Batch 8, Loss: 6.660981776848213, Batch Size: 32\n",
      "Epoch 4, Batch 9, Loss: 7.871083411932518, Batch Size: 32\n",
      "Epoch 4, Batch 10, Loss: 9.015765629795245, Batch Size: 32\n",
      "Epoch 4, Batch 11, Loss: 8.678804138040523, Batch Size: 32\n",
      "Epoch 4, Batch 12, Loss: 7.240848625283746, Batch Size: 32\n",
      "Epoch 4, Batch 13, Loss: 8.701185646438692, Batch Size: 32\n"
     ]
    }
   ],
   "source": [
    "params = model.get_params()\n",
    "optimizer = Adam(params)\n",
    "\n",
    "# Train the model\n",
    "train(train_batches, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7e4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test(test_batches, model)\n",
    "test_mc(test_batches, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2b54f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
